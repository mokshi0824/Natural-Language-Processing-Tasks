{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tGaW3Irz6mIOmoPQntmh1-6QV9TjuVvY",
      "authorship_tag": "ABX9TyN7h0dCr4y4/heci1OEnFK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokshi0824/Natural-Language-Processing-Tasks/blob/main/Task_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download once (if not already)\n",
        "import nltk\n",
        "\n",
        "# Download once (if not already)\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')  # <-- add this\n",
        "\n",
        "\n",
        "# === File Input ===\n",
        "file_path = input(\"/content/drive/MyDrive/NLP/Nlp.txt: \")\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(\"\\nNumber of lines in file:\", len(lines))\n",
        "\n",
        "# POS tags we want\n",
        "extract_tags = {\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"PRP\",\"PRP$\"}\n",
        "\n",
        "# === Process each line ===\n",
        "for i, line in enumerate(lines, start=1):\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        continue\n",
        "    tokens = nltk.word_tokenize(line)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    extracted = [(w,t) for w,t in pos_tags if t in extract_tags]\n",
        "\n",
        "    print(f\"\\nLine {i}: {line}\")\n",
        "    print(\"Tagged Output:\", pos_tags)\n",
        "    print(\"Extracted Info:\", extracted)"
      ],
      "metadata": {
        "id": "2Lmo9VZ7XFex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc97ee00-cff5-42d5-c023-54912840bff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/Nlp.txt: /content/drive/MyDrive/NLP/Nlp.txt\n",
            "\n",
            "Number of lines in file: 5\n",
            "\n",
            "Line 1: Alice went to the park with her friends.\n",
            "Tagged Output: [('Alice', 'NNP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('park', 'NN'), ('with', 'IN'), ('her', 'PRP$'), ('friends', 'NNS'), ('.', '.')]\n",
            "Extracted Info: [('Alice', 'NNP'), ('park', 'NN'), ('her', 'PRP$'), ('friends', 'NNS')]\n",
            "\n",
            "Line 2: Bob loves programming in Python.\n",
            "Tagged Output: [('Bob', 'NNP'), ('loves', 'VBZ'), ('programming', 'VBG'), ('in', 'IN'), ('Python', 'NNP'), ('.', '.')]\n",
            "Extracted Info: [('Bob', 'NNP'), ('Python', 'NNP')]\n",
            "\n",
            "Line 3: They are planning a trip to London next month.\n",
            "Tagged Output: [('They', 'PRP'), ('are', 'VBP'), ('planning', 'VBG'), ('a', 'DT'), ('trip', 'NN'), ('to', 'TO'), ('London', 'NNP'), ('next', 'JJ'), ('month', 'NN'), ('.', '.')]\n",
            "Extracted Info: [('They', 'PRP'), ('trip', 'NN'), ('London', 'NNP'), ('month', 'NN')]\n",
            "\n",
            "Line 4: My brother plays football and cricket.\n",
            "Tagged Output: [('My', 'PRP$'), ('brother', 'NN'), ('plays', 'VBZ'), ('football', 'NN'), ('and', 'CC'), ('cricket', 'NN'), ('.', '.')]\n",
            "Extracted Info: [('My', 'PRP$'), ('brother', 'NN'), ('football', 'NN'), ('cricket', 'NN')]\n",
            "\n",
            "Line 5: The teacher gave us homework for the weekend.\n",
            "Tagged Output: [('The', 'DT'), ('teacher', 'NN'), ('gave', 'VBD'), ('us', 'PRP'), ('homework', 'NN'), ('for', 'IN'), ('the', 'DT'), ('weekend', 'NN'), ('.', '.')]\n",
            "Extracted Info: [('teacher', 'NN'), ('us', 'PRP'), ('homework', 'NN'), ('weekend', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIgBZD9J0ciM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}